    \section{矩阵向量求导}
    更多基本公式和例子详见：\url{https://www.cnblogs.com/pinard/p/10791506.html} 或 \url{https://zhuanlan.zhihu.com/p/24709748} 或 \url{https://github.com/LynnHo/Matrix-Calculus}
    \subsection{求导布局}
    \begin{enumerate}
        \item 分子布局(numerator layout): 求导结果的维度以分子为主
        \item 分母布局(denominator layout): 求导结果的维度以分母为主
        \item 混合布局：即如果是向量或者矩阵对标量求导，则使用分子布局为准；如果是标量对向量或者矩阵求导，则以分母布局为准。对于向量对向量求导(有些分歧),以分子布局的雅克比矩阵为主。
    \end{enumerate}
    \textbf{定义}：
    \begin{itemize}
        \item $x$--->标量 \quad $\bf{x}$--->n维向量 \quad $\bf{X}$--->$m \times n$矩阵
        \item $y$--->标量 \quad $\bf{y}$--->m维向量 \quad $\bf{Y}$--->$p \times q$矩阵
    \end{itemize}
    两者相差一个\textbf{转置}，例子：标量$\bf{y}$对矩阵$\bf{X}$求导，那么如果按分母布局，则求导结果的维度和矩阵$\bf{X}$的维度m×n是一致的。如果是分子布局，则求导结果的维度为n×m。


    所以，\textbf{标量}对\textbf{向量或矩阵}求导，\textbf{向量或矩阵}对\textbf{标量}求导这四种情况，对应的分子布局和分母布局的排列方式已经确定了。


    \textbf{向量对向量的求导}：(只讨论列向量，行向量求导只相差一个转置) \\
    m维列向量$\bf{y}$对n维列向量$\bf{x}$求导，一共有$mn$个标量对标量求导。


    \textbf{分子布局}，结果矩阵的第一维度以分子为准，即为$m\times n$矩阵(\textbf{雅克比矩阵})：\\
    $\frac{\partial \mathbf{y}}{\partial \mathbf{x}}(or \frac{\partial \mathbf{y}}{\partial \mathbf{x}^{\mathbf{T}}})=\left(\begin{array}{cccc}{\frac{\partial y_{1}}{\partial x_{1}}} & {\frac{\partial y_{1}}{\partial x_{2}}} & {\cdots} & {\frac{\partial y_{1}}{\partial x_{n}}} \\ {\frac{\partial y_{2}}{\partial x_{1}}} & {\frac{\partial y_{2}}{\partial x_{2}}} & {\cdots} & {\frac{\partial y_{2}}{\partial x_{n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial y_{m}}{\partial x_{1}}} & {\frac{\partial y_{m}}{\partial x_{2}}} & {\cdots} & {\frac{\partial y_{m}}{\partial x_{n}}}\end{array}\right)$


    \textbf{分母布局}，结果矩阵的第一维度以分母为准，即为$n\times m$矩阵(\textbf{梯度矩阵})： \\
    $\frac{\partial \mathbf{y}}{\partial \mathbf{x}}(or \frac{\partial \mathbf{y^{T}}}{\partial \mathbf{x}})=\left(\begin{array}{cccc}{\frac{\partial y_{1}}{\partial x_{1}}} & {\frac{\partial y_{2}}{\partial x_{1}}} & {\ldots} & {\frac{\partial y_{m}}{\partial x_{1}}} \\ {\frac{\partial y_{1}}{\partial x_{2}}} & {\frac{\partial y_{2}}{\partial x_{2}}} & {\cdots} & {\frac{\partial y_{m}}{\partial x_{2}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial y_{1}}{\partial x_{n}}} & {\frac{\partial y_{2}}{\partial x_{n}}} & {\cdots} & {\frac{\partial y_{m}}{\partial x_{n}}}\end{array}\right)$
    \\
    上述两种布局简单思路就是，以谁做布局就用谁的维度作为结果矩阵的第一个维度，即看成列，另一个向量则看成行。

    \subsection{矩阵向量求导---定义法}
    \subsubsection{标量对向量求导}
    标量对向量求导，严格来说是\textbf{实值函数}对向量的求导。即定义实值函数$f: R^{n} \rightarrow R$，也即$f( \bm{x} )=y$(这里f,y均代表标量)，自变量$\bm{x}$是n维向量，$y$是标量。


    所谓标量对向量的求导，其实就是\textbf{标量对向量里的每个分量分别求导，最后把求导的结果排列在一起，按一个向量表示而已}。所以\textbf{将实值函数对向量的每一个分量来求导，最后找到规律，得到求导的结果向量。}
    \\
    \textbf{例子：}$y=\mathbf{a}^{T} \mathbf{x}$，求解$\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial \mathbf{x}}$
    \\
    根据定义，我们先对$\bm{x}$的第i个分量进行求导，这是一个标量对标量的求导，如：$\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial x_{i}}=\frac{\partial \sum_{j=1}^{n} a_{j} x_{j}}{\partial x_{i}}=\frac{\partial a_{i} x_{i}}{\partial x_{i}}=a_{i}$
    \\
    所以对向量的第i个分量的求导结果就等于向量a的第i个分量。由于是分母布局，最后所有求导结果的分量组成的是一个n维向量。即为向量a：$\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial \mathbf{x}}=\mathbf{a}$
    \\
    同理：$\frac{\partial \mathbf{x}^{T} \mathbf{a}}{\partial \mathbf{x}}=\mathbf{a}$
    \\
    \textbf{例子：}$y=\mathbf{x}^{T} \mathbf{A} \mathbf{x}$，求解$\frac{\partial \mathbf{x}^{T} \mathbf{A} \mathbf{x}}{\partial \mathbf{x}}$
    \\
    对$\bm{x}$的第k个分量求导：\\
    $\frac{\partial \mathbf{x}^{T} \mathbf{A} \mathbf{x}}{\partial x_{k}}=\frac{\partial \sum_{i=1}^{n} \sum_{j=1}^{n} x_{i} A_{i j} x_{j}}{\partial x_{k}}=\sum_{i=1}^{n} A_{i k} x_{i}+\sum_{j=1}^{n} A_{k j} x_{j}=\mathbf{A}^{T} \mathbf{x}+\mathbf{A} \mathbf{x}$
    \subsubsection{标量对向量求导的基本法则}
    \begin{itemize}
        \item \textbf{常量}对向量的求导结果为0
        \item 线性法则：如果$f,g$都是实值函数，$c_1,c_2$为常数，则：$\frac{\partial\left(c_{1} f(\mathbf{x})+c_{2} g(\mathbf{x}))\right.}{\partial \mathbf{x}}=c_{1} \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}+c_{2} \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}$
        \item 乘法法则：如果$f,g$都是实值函数，则：$\frac{\partial f(\mathbf{x}) g(\mathbf{x})}{\partial \mathbf{x}}=f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}+\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} g(\mathbf{x})$
        \item 除法法则：如果$f,g$都是实值函数，且$g(x)≠0$，则：$\frac{\partial f(\mathbf{x}) / g(\mathbf{x})}{\partial \mathbf{x}}=\frac{1}{g^{2}(\mathbf{x})}\left(g(\mathbf{x}) \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}-f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}\right)$
    \end{itemize}

    \subsubsection{标量对矩阵求导}
    \textbf{例子：}$y=\mathbf{a}^{T} \mathbf{X} \mathbf{b}$，求解$\frac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{b}}{\partial \mathbf{X}}$，其中, $\bm{a}$是m维向量,$\bm{b}$是n维向量,$\bm{X}$是m×n的矩阵
    \\
    对矩阵$\bm{X}$的任意一个位置的$\bm{X}_{ij}$求导：
    \\
    $\dfrac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{b}}{\partial X_{i j}}=\dfrac{\partial \sum_{p=1}^{m} \sum_{q=1}^{n} a_{p} X_{p q} b_{q}}{\partial X_{i j}}=\dfrac{\partial a_{i} X_{i j} b_{j}}{\partial X_{i j}}=a_{i} b_{j}$(从行空间视角做矩阵乘法)
    即求导结果在(i.j)位置的求导结果是a向量第i个分量和b第j个分量的乘积，将所有的位置的求导结果排列成一个m×n的矩阵，即为$ab^T$,这样最后的求导结果为：$\dfrac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{b}}{\partial \mathbf{X}}=a b^{T}$
    \textbf{标量对矩阵求导也有和第二节对向量求导类似的基本法则}

    \subsubsection{向量对向量求导}
    \textbf{例子：}$\mathbf{y}=\mathbf{A} \mathbf{x}$，其中$\mathbf{A}$为n×m的矩阵，$\mathbf{x}, \mathbf{y}$分别为m,n维向量。求解$\frac{\partial \mathbf{A} \mathbf{x}}{\partial \mathbf{x}}$：
    \\
    $(n\times 1)$对$(m\times 1)$求导，按照分子布局，结果应是一个$n\times m$矩阵
    \\
    先求矩阵的第i行和向量的内积对向量的第j分量求导，用定义法求解过程如下：$\dfrac{\partial \mathbf{A}_{\mathbf{i}} \mathbf{x}}{\partial \mathbf{x}_{\mathbf{j}}}=\dfrac{\partial A_{i j} x_{j}}{\partial \mathbf{x}_{\mathbf{j}}}=A_{i j}$
    \\
    所以矩阵$A$的第i行和向量的内积对向量的第j分量求导的结果是矩阵 A的(i,j)位置的值。由于是分子布局，所以排列出的结果是$A$,而不是$A^T$

    \subsection{矩阵微分}
    标量的导数和微分：$d f=f^{\prime}(x) d x$(单变量),若是多变量，则：$d f=\sum_{i=1}^{n} \dfrac{\partial f}{\partial x_{i}} d x_{i}=\left(\dfrac{\partial f}{\partial \mathbf{x}}\right)^{T} d \mathbf{x}$(多元向量值函数的微分)
    可以看出标量对向量的求导$\dfrac{\partial f}{\partial \mathbf{x}}$(列向量)与标量的向量微分$d f$\textbf{有一个转置的关系}！


    推广到\textbf{变元是矩阵的情况}：
    $d f=\sum_{i=1}^{m} \sum_{j=1}^{n} \dfrac{\partial f}{\partial X_{i j}} d X_{i j}=\operatorname{tr}\left(\left(\dfrac{\partial f}{\partial \mathbf{X}}\right)^{T} d \mathbf{X}\right)$，其中迹函数等于主对角线的和：$\operatorname{tr}\left(A^{T} B\right)=\sum_{i, j} A_{i j} B_{i j}$(\textbf{$A, B$必须同型，且此处是逐元素点乘。})


    此公式可以把A和B均看做列向量来理解，矩阵同理！內积是两个矩阵相同的对应位置上元素乘积之和。因为两个矩阵相乘，A中第$A_{ij}$个元素乘以B中第$B_{ij}$个元素的积，全部在形成的矩阵对角线上。(可以举例子理解)


    矩阵微分和它的导数也有一个转置的关系，只是在外面套了一个迹函数。由于标量的迹函数就是它本身，那么矩阵微分和向量微分可以统一表示，即：$d f=\operatorname{tr}\left(\left(\dfrac{\partial f}{\partial \mathbf{X}}\right)^{T} d \mathbf{X}\right) \quad d f=\operatorname{tr}\left(\left(\dfrac{\partial f}{\partial \mathbf{x}}\right)^{T} d \mathbf{x}\right)$

    \subsubsection{矩阵向量求导---微分法(标量对向量或矩阵的求导)}
    \textbf{求解方法(因变量须为标量)：}若标量函数$f$是矩阵$\bm{X}$经加减乘法、逆、行列式、逐元素函数等运算构成，则使用相应的运算法则对$f$求微分，再使用迹函数技巧给$df$套上迹并将其它项交换至$d\bm{X}$左侧,那么对于迹函数里面在$d\bm{X}$左边的部分，只需要加一个转置便可以得到导数。


    \textbf{迹函数常用技巧：}
    \begin{enumerate}
        \item 标量的迹等于自己：$\operatorname{tr}(x)=x$
        \item 转置不变：$\operatorname{tr}\left(A^{T}\right)=\operatorname{tr}(A)$
        \item 交换律：$\operatorname{tr}(A B)=\operatorname{tr}(B A)$，需要满足$A,B^T$同维度，实质上就是$A,B$相容，并且由于前面加了$tr()$，所以最后结果是一个方阵。其证明过程保存在chrome矩阵分析书签中，其中需要注意比较$tr(AB)$和$tr(BA)$的代数表达式时，交换两个求和符号实质上就是从AB->BA的矩阵相乘(行乘列)，仔细比较下标即可发现。
        \item 加减法：$\operatorname{tr}(X+Y)=\operatorname{tr}(X)+\operatorname{tr}(Y), \operatorname{tr}(X-Y)=\operatorname{tr}(X)-\operatorname{tr}(Y)$
        \item 矩阵乘法和迹交换：$\operatorname{tr}\left((A \odot B)^{T} C\right)=\operatorname{tr}\left(A^{T}(B \odot C)\right)$，需要满足$A,B,C$同维度。(中间是哈达玛积，此式利用了前面提到的迹函数等于主对角线的和一式)
    \end{enumerate}




    \textbf{例子：}$y=\mathbf{a}^{T} \mathbf{X} \mathbf{b}$，求解$\frac{\partial y}{\partial \mathbf{X}}$
    \begin{enumerate}
        \item 对$f$求微分：$d y=d \mathbf{a}^{T} \mathbf{X} \mathbf{b}+\mathbf{a}^{T} d \mathbf{X} \mathbf{b}+\mathbf{a}^{T} \mathbf{X} d \mathbf{b}=\mathbf{a}^{T} d \mathbf{X} \mathbf{b}$(因变量部分不是自变量的函数，因此导数为0，直接省略了)
        \item 两边套上迹函数：$d y=\operatorname{tr}(d y)=\operatorname{tr}\left(\mathbf{a}^{T} d \mathbf{X} \mathbf{b}\right)=\operatorname{tr}\left(\mathbf{b} \mathbf{a}^{T} d \mathbf{X}\right)$
        \item 根据矩阵导数和微分的定义，迹函数里面在$d\bm{X}$左边的部分$\bm{ba}^T$,加上一个转置即为要求的导数，即：$\frac{\partial f}{\partial \mathbf{X}}=\left(\mathbf{b} \mathbf{a}^{T}\right)^{T}=\bm{a b}^{T}$
    \end{enumerate}
    \textbf{例子：}$y=\mathbf{a}^{T} \exp (\mathbf{X} \mathbf{b})$，求解$\frac{\partial y}{\partial \mathbf{X}}$
    \begin{enumerate}
        \item $d y=\operatorname{tr}(d y)=\operatorname{tr}\left(\mathbf{a}^{T} \operatorname{dexp}(\mathbf{X b})\right)$(因变量部分不是自变量的函数，因此导数为0。$d\bm{a}^T=0$省略了)
        \item $=\operatorname{tr}\left(\mathbf{a}^{T}(\exp (\mathbf{X} \mathbf{b}) \odot d(\mathbf{X} \mathbf{b}))\right)$(这里使用了逐元素求导$d \sigma(X)=\sigma^{\prime}(X) \odot d X$，$exp^{\prime}(x)=exp(x)$)
        \item $=\operatorname{tr}\left((\mathbf{a} \odot \exp (\mathbf{X} \mathbf{b}))^{T} d \mathbf{X} \mathbf{b}\right)$(这里$d(\bm{X}b)$展开后$= d\bm{X}\cdot \bm{b} + \bm{X}\cdot d\bm{b}$，后一项为0所以省略)
        \item $=\operatorname{tr}\left((\mathbf{a} \odot \exp (\mathbf{X} \mathbf{b}))^{T} d \mathbf{X} \cdot \mathbf{b}\right)$(这里验证前后两部分的维度呈转置关系，可以利用迹的交换律把$\bm{b}$放到最前面)
        \item $=\operatorname{tr}\left(\mathbf{b}(\mathbf{a} \odot \exp (\mathbf{X b}))^{T} d \mathbf{X}\right)$
    \end{enumerate}
    所以结果为：$\dfrac{\partial y}{\partial \mathbf{X}}=(\mathbf{a} \odot \exp (\mathbf{X} \mathbf{b})) b^{T}$
    \subsubsection{向量矩阵的迹函数对向量矩阵求导(也是标量对向量矩阵求导)}
    $\dfrac{\partial \operatorname{tr}(A B)}{\partial A}=B^{T}$($A,B^T$同型)，按照矩阵微分定义(张贤达矩阵分析与应用3.2.1: \quad $\mathrm{d}(\operatorname{tr} \boldsymbol{U})=\operatorname{tr}(\mathrm{d} \boldsymbol{U})$)：
    \\
    $d\operatorname{tr}(AB)=\operatorname{tr}(d(AB))=\operatorname{tr}(dA \cdot B + A\cdot dB)=\operatorname{tr}(dA \cdot B)=\operatorname{tr}(B \cdot dA)$；
    同理，$\dfrac{\partial \operatorname{tr}(A B)}{\partial B}=A^{T}$。
    \\
    求解$\dfrac{\partial t r\left(W^{T} A W\right)}{\partial W}$(张贤达一书3.2.1: $d\left(\boldsymbol{X}^{\mathrm{T}}\right)=(d \boldsymbol{X})^{\mathrm{T}}$)：
    \\
    $d\left(\operatorname{tr}\left(W^{T} A W\right)\right)=\operatorname{tr}\left(d W^{T} A W+W^{T} A d W\right)=\operatorname{tr}\left(d W^{T} A W\right)+\operatorname{tr}\left(W^{T} A d W\right)=\operatorname{tr}\left((d W)^{T} A W\right)+\operatorname{tr}\left(W^{T} A d W\right)=\operatorname{tr}\left(W^{T} A^{T} d W\right)+\operatorname{tr}\left(W^{T} A d W\right)=\operatorname{tr}\left(W^{T}\left(A+A^{T}\right) d W\right)$
    \\
    所以结果为：$\dfrac{\partial \operatorname{tr}\left(W^{T} A W\right)}{\partial W}=\left(A+A^{T}\right) W$
    \\
    求解$\dfrac{\partial \operatorname{tr}\left(B^{T} X^{T} C X B\right)}{\partial X}$：
    \\
    $d\left(\operatorname{tr}\left(B^{T} X^{T} C X B\right)\right)=\operatorname{tr}\left(B^{T} d X^{T} C X B\right)+\operatorname{tr}\left(B^{T} X^{T} C d X B\right)=\operatorname{tr}\left((d X)^{T} C X B B^{T}\right)+\operatorname{tr}\left(B B^{T} X^{T} C d X\right)=\operatorname{tr}\left(B B^{T} X^{T} C^{T} d X\right)+\operatorname{tr}\left(B B^{T} X^{T} C d X\right)=\operatorname{tr}\left(\left(B B^{T} X^{T} C^{T}+B B^{T} X^{T} C\right) d X\right)$
    \\
    因此：$\dfrac{\partial \operatorname{tr}\left(B^{T} X^{T} C X B\right)}{\partial X}=\left(C+C^{T}\right) X B B^{T}$

    \subsection{矩阵向量求导---链式法则}
    \subsubsection{向量对向量求导(分子布局)}
    假设多个向量存在依赖关系，如：$\mathbf{x} \rightarrow \mathbf{y} \rightarrow \mathbf{z}$，则有以下链式求导法则：$\dfrac{\partial \mathbf{z}}{\partial \mathbf{x}}=\dfrac{\partial \mathbf{z}}{\partial \mathbf{y}} \dfrac{\partial \mathbf{y}}{\partial \mathbf{x}}$；
    但是要求所有有依赖关系的变量都是向量，不能是矩阵或标量！
    \\
    从矩阵维度相容的角度来理解上述链式法则：假设$\mathbf{x}, \mathbf{y}, \mathbf{z}$分别是m,n,p维向量，则求导结果$\frac{\partial \mathbf{z}}{\partial \mathbf{x}}$是一个p×m的雅克比矩阵，而右边$\frac{\partial \mathbf{z}}{\partial \mathbf{y}}$是一个p×n的雅克比矩阵，$\frac{\partial \mathbf{y}}{\partial \mathbf{x}}$是一个n×m的矩阵，两个雅克比矩阵的乘积维度刚好是p×m，和左边相容。

    \subsubsection{标量对多个向量求导}
    机器学习算法中，最终要优化的一般是一个标量损失函数，因此最后求导的目标是标量，如：$\mathbf{x} \rightarrow \mathbf{y} \rightarrow z$，按照上一小节易发现维度不相容。
    \\
    假设$\bm{x,y}$分别是m,n维向量, 那么$\dfrac{\partial z}{\partial \bm{x}}$的求导结果是一个m×1的向量，$\dfrac{\partial z}{\partial \bm{y}}$是一个n×1的向量，$\dfrac{\partial \mathbf{y}}{\partial \mathbf{x}}$是一个n×m的雅克比矩阵,右边的向量和矩阵是没法直接乘的。
    \\
    \begin{enumerate}
        \item 假如把标量求导的部分都做一个转置，则维度就可以相容了：$\left(\dfrac{\partial z}{\partial \mathbf{x}}\right)^{T}=\left(\dfrac{\partial z}{\partial \mathbf{y}}\right)^{T} \dfrac{\partial \mathbf{y}}{\partial \mathbf{x}}$
        \item 然后两边再转置得到\textbf{标量对多个向量求导的链式法则：}$\dfrac{\partial z}{\partial \mathbf{x}}=\left(\dfrac{\partial \mathbf{y}}{\partial \mathbf{x}}\right)^{T} \dfrac{\partial z}{\partial \mathbf{y}}$
        \item 如果是\textbf{标量对更多的向量求导},比如$\mathbf{y}_{1} \rightarrow \mathbf{y}_{2} \rightarrow \ldots \rightarrow \mathbf{y}_{n} \rightarrow z$，则其链式求导表达式：$\dfrac{\partial z}{\partial \mathbf{y}_{1}}=\left(\dfrac{\partial \mathbf{y}_{\mathbf{n}}}{\partial \mathbf{y}_{\mathbf{n}-1}} \dfrac{\partial \mathbf{y}_{\mathbf{n}-\mathbf{1}}}{\partial \mathbf{y}_{\mathbf{n}-\mathbf{2}}} \cdots \dfrac{\partial \mathbf{y}_{\mathbf{2}}}{\partial \mathbf{y}_{\mathbf{1}}}\right)^{T} \dfrac{\partial z}{\partial \mathbf{y}_{\mathbf{n}}}$
    \end{enumerate}

    \textbf{另一种求复合函数导数的思路：}
    \\
    假设已求得$\dfrac{\partial f}{\partial Y}$，而Y是X的函数，如何求$\dfrac{\partial f}{\partial X}$？可以直接从微分入手建立复合法则：先写出$d f=\operatorname{tr}\left(\frac{\partial f^{T}}{\partial Y} d Y\right)$，再将dY用dX表示出来代入，并使用迹技巧将其他项交换至dX左侧，即可得到$\dfrac{\partial f}{\partial X}$。


    举个例子，$Y=AXB$, 此时
    \\
    $d f=\operatorname{tr}\left(\dfrac{\partial f^{T}}{\partial Y} d Y\right)=\operatorname{tr}\left(\dfrac{\partial f^{T}}{\partial Y} A d X B\right)=\operatorname{tr}\left(B \dfrac{\partial f^{T}}{\partial Y} A d X\right)=\operatorname{tr}\left(\left(A^{T} \dfrac{\partial f}{\partial Y} B^{T}\right)^{T} d X\right)$，
    \\
    可得$\dfrac{\partial f}{\partial X}=A^{T} \dfrac{\partial f}{\partial Y} B^{T}$！

    \textbf{最小二乘法例子：}


    \textbf{(链式)：} $l=(X \bm{\theta-y})^{T}(X \bm{\theta-y})$，优化的损失函数$l$是一个标量，模型参数$\bm{\bm{\theta}}$是一个向量。假设向量$\bm{\bm{z}}=X \bm{\theta-y}$($\bm{z}$是向量)，则$l=\bm{z}^{T} \bm{z}$，$\bm{\theta} \rightarrow \bm{z} \rightarrow l$存在链式求导关系，因此：$\dfrac{\partial l}{\partial \bm{\theta}}=\left(\dfrac{\partial \bm{z}}{\partial \bm{\theta}}\right)^{T} \dfrac{\partial l}{\partial \mathbf{\bm{z}}}=X^{T}(2 \bm{z})=2 X^{T}(X \bm{\theta}-y)$。


    其中用到的求导公式：$\dfrac{\partial (X \bm{\theta}-y)}{\partial \bm{\theta}}=X$(分子是向量，向量对向量求导，定义法，使用分子布局)，$\dfrac{\partial \bm{z}^{T} \bm{z}}{\partial \bm{z}}=2 \bm{z}$(分子是标量,标量对向量求导，使用分母布局)。

    \textbf{(微分法)：} 因为$l$是一个标量，所以可以用前面的微分法来进行求导！
    \begin{enumerate}
        \item $d(l) = \operatorname{tr}(d(l))= \operatorname{tr}\left[d(\theta^T X^T X \theta)-d(\theta^T X^T y)- d(y^T X \theta)\right]$
        \\
        = $\operatorname{tr}\left[d(\theta^T) X^T X\theta + \theta^T X^T Xd\theta -d(\theta^T)X^T y - y^TXd\theta \right]$
        \\
        = $\operatorname{tr}[d(\theta^T) X^T X\theta] + \operatorname{tr}(\theta^T X^T Xd\theta) - \operatorname{tr}[d(\theta^T)X^T y] -\operatorname{tr}(y^TXd\theta)$
        \\
        = $\operatorname{tr}(\theta^T X^T X d\theta) + \operatorname{tr}(\theta^T X^T Xd\theta) - \operatorname{tr}(y^TXd\theta) -\operatorname{tr}(y^TXd\theta)$
        \\
        = $2\operatorname{tr}(\theta^T X^T X d\theta) - 2\operatorname{tr}(y^TXd\theta)$
        \\
        = $\operatorname{tr}[2 (\theta^T X^T - y^T)X d\theta]$
        \\
        = $\operatorname{tr}\left\{[2 X^T (X \theta - y)]^T d\theta\right\}$(这里的$\bm{\theta}$和$\bm{y}$均为列向量)
        \item 所以由微分法可得：$\dfrac{\partial l}{\partial \bm{\theta}}=2 X^{T}(X \boldsymbol{\theta}-\bm{y})$
        \item \textbf{第1步繁琐，应该为：}$d(l)=(\bm{X} d \bm{\theta})^{T}(\bm{X} \bm{\theta}-\bm{y})+(\bm{X} \bm{\theta}-\bm{y})^{T}(\bm{X} d \bm{\theta})=2(\bm{X} \bm{\theta}-\bm{y})^{T} \bm{X} d \bm{\theta}$，$\dfrac{\partial l}{\partial \bm{w}}=2 \bm{X}^{T}(\bm{X} \bm{\theta}-\boldsymbol{y})$
        \item $\dfrac{\partial l}{\partial \boldsymbol{\theta}}=\mathbf{0}$ 即 $\bm{X}^{T} \bm{X} \boldsymbol{\theta}=\bm{X}^{T} \boldsymbol{y}$, 故$\bm{\theta}$的最小二乘估计为$\boldsymbol{\theta}=\left(\bm{X}^{T} \bm{X}\right)^{-1} \bm{X}^{T} \boldsymbol{y}$
    \end{enumerate}

    \subsection{标量对多个矩阵求导}
    假设有这样的依赖关系：$\mathbf{X} \rightarrow \mathbf{Y} \rightarrow z$，回顾多元复合函数的求导法则(只要涉及到求导自变量的中间变量都要进行求偏导，且最后结果累加)，有：
    \\
    $\dfrac{\partial z}{\partial x_{i j}}=\sum_{k, l} \dfrac{\partial z}{\partial Y_{k l}} \dfrac{\partial Y_{k l}}{\partial X_{i j}}=\operatorname{tr}\left(\left(\dfrac{\partial z}{\partial Y}\right)^{T} \dfrac{\partial Y}{\partial X_{i j}}\right)$


    这里没有给出基于矩阵整体的链式求导法则，主要原因是矩阵对矩阵的求导是比较复杂的定义，目前也未涉及。因此\textbf{只能给出对矩阵中一个标量的链式求导方法}。这个方法并不实用，因为我们并不想每次都基于定义法来求导最后再去排列求导结果。


    这里的$\sum_{k,l}$是什么意思？\textbf{应该是指标量z对整个矩阵Y逐元素的进行求偏导，再通过链式法则让后面的对应矩阵Y元素对自变量$X_{ij}$求导，然后把所有结果累加起来！}。


    \textbf{例1：}$A,B,X,Y$都是矩阵，$z$是标量，其中$z=f(Y), Y=A X+B$，求$\dfrac{\partial z}{\partial X}$

    \begin{enumerate}
        \item 这里使用\textbf{定义法}，先用上面的标量链式求导公式$\dfrac{\partial z}{\partial x_{i j}}=\sum_{k, l} \dfrac{\partial z}{\partial Y_{k l}} \dfrac{\partial Y_{k l}}{\partial X_{i j}}$
        \item 后半部分的求导：$\dfrac{\partial Y_{k l}}{\partial X_{i j}}=\dfrac{\partial \sum_{s}\left(A_{k s} X_{s l}\right)}{\partial X_{i j}}=\dfrac{\partial A_{k i} X_{i l}}{\partial X_{i j}}=A_{k i} \delta_{l j}$，其中$\delta_{lj}=\left\{\begin{array}{ll}1 & l=j \\ 0 & l \neq j\end{array}\right.$ 这里$\sum_{s}(A_{k s} X_{s l})$表示行乘列运算，代表结果矩阵$Y$中的元素$Y_{kl}$。
        \item 故最终转化为：$\dfrac{\partial z}{\partial x_{i j}}=\sum_{k, l} \dfrac{\partial z}{\partial Y_{k l}} A_{k i} \delta_{l j}=\sum_{k} \dfrac{\partial z}{\partial Y_{k j}} A_{k i}$
        \item 然后将标量对矩阵中单个元素求偏导的结果进行排列，首先$\sum_{k} \dfrac{\partial z}{\partial Y_{k j}}$是求偏导结果矩阵$\dfrac{\partial z}{\partial Y}$的第$j$列，然后$\sum_{k} A_{ki}$转置过来就是后半部分结果矩阵$A^T$的第$i$行,所以排列成矩阵即为：$\dfrac{\partial z}{\partial X}=A^{T} \dfrac{\partial z}{\partial Y}$
        \item 总结： \\ $z=f(Y), Y=A X+B \rightarrow \dfrac{\partial z}{\partial X}=A^{T} \dfrac{\partial z}{\partial Y}$；\\ 当$\bm{x}$是一个向量的时候也成立：\\ $z=f(\mathbf{y}), \mathbf{y}=A \mathbf{x}+\mathbf{b} \rightarrow \dfrac{\partial z}{\partial \mathbf{x}}=A^{T} \dfrac{\partial z}{\partial \mathbf{y}}$
        \item 如果要求导的自变量在左边，线性变换在右边，也有类似稍有不同的结论如下：\\ $z=f(Y), Y=X A+B \rightarrow \dfrac{\partial z}{\partial X}=\dfrac{\partial z}{\partial Y} A^{T}$ \\ $z=f(\mathbf{y}), \mathbf{y}=X \mathbf{a}+\mathbf{b} \rightarrow \dfrac{\partial z}{\partial \mathbf{X}}=\dfrac{\partial z}{\partial \mathbf{y}} a^{T}$
    \end{enumerate}


    \textbf{(对上述第6步额外两条公式求解)}
    \\
    \textbf{例2：}$z=f(Y), Y=XA+B$，求$\dfrac{\partial z}{\partial X}$
    \begin{enumerate}
        \item \textbf{定义法：}$\dfrac{\partial z}{\partial x_{i j}}=\sum_{k, l} \dfrac{\partial z}{\partial Y_{k l}} \dfrac{\partial Y_{k l}}{\partial X_{i j}}$
        \item 后半部分的求导：$\dfrac{\partial Y_{k l}}{\partial X_{i j}}=\dfrac{\partial \sum_{s}\left(X_{k s} A_{s l}\right)}{\partial X_{i j}}=\dfrac{\partial X_{k j} A_{j l}}{\partial X_{i j}}=\delta_{k j} A_{j l} $，其中$\delta_{kj}=\left\{\begin{array}{ll}1 & k=i \\ 0 & k \neq i\end{array}\right.$ 这里$\sum_{s}(X_{k s} A_{s l})$表示行乘列运算，代表结果矩阵$Y$中的元素$Y_{kl}$
        \item 最终转化为：$\dfrac{\partial z}{\partial x_{i j}}=\sum_{k, l} \dfrac{\partial z}{\partial Y_{k l}} \delta_{k j} A_{j l} =\sum_{l} \dfrac{\partial z}{\partial Y_{i l}} A_{j l}$
        \item 将标量对矩阵中单个元素求偏导的结果进行排列，首先看$\dfrac{\partial z}{\partial x_{ij}}$在最终结果矩阵中的下标为ij，说明是两个矩阵相乘(第i行乘第j列的结果)，所以$\sum_{l} \dfrac{\partial z}{\partial Y_{i l}}$是求偏导结果矩阵$\dfrac{\partial z}{\partial Y}$的第$i$行，然后$\sum_{l} A_{jl}$转置过来就是后半部分结果矩阵$A^T$的第$j$列,所以排列成矩阵即为：$\dfrac{\partial z}{\partial X}=\dfrac{\partial z}{\partial Y}A^{T} $
    \end{enumerate}


    \textbf{例3：}$z=f(\mathbf{y}), \mathbf{y}_{m \times 1}=X_{m\times n} \mathbf{a}_{n\times 1}+\mathbf{b}_{m\times 1}$ 求 $\dfrac{\partial z}{\partial \mathbf{X}}$(a是向量，X是矩阵)
    \begin{enumerate}
        \item 还是定义法：$\dfrac{\partial z}{\partial X_{i j}}=\sum_{k} \dfrac{\partial z}{\partial \bm{y}_{k}} \dfrac{\partial \bm{y}_{k}}{\partial X_{i j}}$
        \item 其中后半部分求导：$\dfrac{\partial \bm{y}_{k}}{\partial X_{i j}} = \dfrac{\partial \sum_{l}\left(X_{k l} a_{l}\right)}{\partial X_{i j}}=\dfrac{\partial X_{k j} a_{j}}{\partial X_{i j}}=\delta_{k j} a_{j}$，其中$\delta_{kj}=\left\{\begin{array}{ll}1 & k=i \\ 0 & k \neq i\end{array}\right.$ 这里$\sum_{l}(X_{k l} a_{l})$表示行乘列运算，代表结果向量$y$中的元素$\bm{y}_{k}$
        \item 最终转化为：$\dfrac{\partial z}{\partial X_{i j}}=\sum_{k} \dfrac{\partial z}{\partial \bm{y}_{k}} \delta_{k j} a_{j} =\dfrac{\partial z}{\partial \bm{y}_{i}} a_{j}$
        \item 将标量对矩阵中单个元素求偏导的结果进行排列，首先看$\dfrac{\partial z}{\partial X_{ij}}$在最终结果矩阵中的下标为ij，这里说明是两个向量相乘(第i列乘第j行的结果)，所以结果是矩阵！所以$\dfrac{\partial z}{\partial \bm{y}_{i}}$是求偏导结果矩阵($m\times 1$向量)$\dfrac{\partial z}{\partial \bm{y}}$的第$i$行，然后$a_{j}$是后半部分结果矩阵$a^T$($n\times 1$向量)的第$j$列,所以排列成矩阵即为：$\dfrac{\partial z}{\partial X}=\dfrac{\partial z}{\partial \bm{y}}a^{T} $
    \end{enumerate}